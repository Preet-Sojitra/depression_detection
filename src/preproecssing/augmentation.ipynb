{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lr\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"../../dataset_info\"\n",
    "TRAIN_DATASET_DIR = \"../../extracted_audio/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f\"{DIR}/train_split.csv\")\n",
    "\n",
    "depressed = train_df[train_df[\"PHQ_Binary\"] == 1]\n",
    "depressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([308, 309, 311, 319, 330, 332, 337, 338, 339, 345, 346, 348, 351,\n",
       "       353, 354, 355, 359, 362, 367, 372, 376, 377, 384, 389, 405, 410,\n",
       "       414, 421, 426, 440, 453, 461, 641, 673, 677, 680, 684])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depressed_ids = depressed[\"Participant_ID\"].values\n",
    "depressed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "depressed_audio_files = []\n",
    "\n",
    "for file in sorted(os.listdir(TRAIN_DATASET_DIR)):\n",
    "    # if file has S or P or B in filename then skip\n",
    "    if \"S\" in file or \"P\" in file or \"B\" in file:\n",
    "        continue\n",
    "    if int(file.split(\"_\")[0]) in depressed_ids:\n",
    "        depressed_audio_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shiffting the audio\n",
    "def shift_audio(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift    \n",
    "    \n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data\n",
    "\n",
    "def add_noise(data, noise_factor):\n",
    "    noise = np.random.randn(len(data))\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    augmented_data = augmented_data / augmented_data.max()\n",
    "    return augmented_data\n",
    "\n",
    "# Using only pitch and speed as of now\n",
    "def change_pitch(data, sampling_rate, pitch_factor):\n",
    "    return lr.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n",
    "\n",
    "def change_speed(data, speed_factor):\n",
    "    return lr.effects.time_stretch(data, rate=speed_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG_TECHNIQUES = [\"S\", \"P\", \"B\"]\n",
    "\n",
    "def augment_audio(audio_files):\n",
    "    temp_df = train_df.copy()\n",
    "    for tech in AUG_TECHNIQUES:\n",
    "        for file in audio_files:\n",
    "            print(f\"Augmenting {file} using {tech}\")\n",
    "            y,sr = lr.load(os.path.join(TRAIN_DATASET_DIR, file))\n",
    "            \n",
    "            if tech == \"S\":\n",
    "                speed_factor = np.random.uniform(0.8, 1.2)\n",
    "                print(f\"Speed factor: {speed_factor}\")\n",
    "                augmented_data = change_speed(y, speed_factor)\n",
    "                \n",
    "            elif tech == \"P\":\n",
    "                pitch_factor = 0\n",
    "                while pitch_factor == 0:\n",
    "                    pitch_factor = np.random.randint(-3, 3)\n",
    "                \n",
    "                print(f\"Pitch factor: {pitch_factor}\")\n",
    "                augmented_data = change_pitch(y, sr, pitch_factor)\n",
    "            else:\n",
    "                speed_factor = np.random.uniform(0.8, 1.2)\n",
    "                pitch_factor = np.random.randint(-3, 3)\n",
    "                \n",
    "                while pitch_factor == 0:\n",
    "                    pitch_factor = np.random.randint(-3, 3)\n",
    "                \n",
    "                print(f\"Speed factor: {speed_factor}\")\n",
    "                print(f\"Pitch factor: {pitch_factor}\")\n",
    "                augmented_data = change_speed(y, speed_factor)\n",
    "                augmented_data = change_pitch(augmented_data, sr, pitch_factor)\n",
    "                \n",
    "            # save the augmented data\n",
    "            file_name = file.split(\".\")[0]\n",
    "            augmented_file_name = f\"{file_name}_{tech}.wav\"\n",
    "            sf.write(os.path.join(TRAIN_DATASET_DIR, augmented_file_name), augmented_data, sr)\n",
    "            \n",
    "            # get row from train_df and duplicate it\n",
    "            row = train_df[train_df[\"Participant_ID\"] == int(file.split(\"_\")[0])]\n",
    "            new_row = row.copy()\n",
    "            # change id so that it can be distinguished from normal audio\n",
    "            new_row[\"Participant_ID\"] = f\"{int(file.split('_')[0])}_{tech}\" # new id = 308_S\n",
    "            # append new row to train_df\n",
    "            temp_df = pd.concat([temp_df, new_row], ignore_index=True)\n",
    "            print(\"-----------------------\")\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = augment_audio(depressed_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.to_csv(os.path.join(DIR, \"train_split_augmented.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "depressed_audio_files = []\n",
    "\n",
    "for file in sorted(os.listdir(TRAIN_DATASET_DIR)):\n",
    "    # if file has S or P or B in filename then skip\n",
    "    if \"S\" in file or \"P\" in file or \"B\" in file:\n",
    "        depressed_audio_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in depressed_audio_files:\n",
    "    id, _, tech = file.split(\"_\")\n",
    "    row = train_df[train_df[\"Participant_ID\"] == int(id)]\n",
    "    new_row = row.copy()\n",
    "    new_row[\"Participant_ID\"] = f\"{id}_{tech[0]}\"\n",
    "    train_augmented_df = pd.concat([train_augmented_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_df.to_csv(os.path.join(DIR, \"train_split_augmented.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest)",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
