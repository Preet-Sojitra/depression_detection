{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"../../raw-dataset/data_splits/train\"\n",
    "DEV_DIR = \"../../raw-dataset/data_splits/dev\"\n",
    "TEST_DIR = \"../../raw-dataset/data_splits/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Transcripts\n",
    "\n",
    "Som transcipts contains a some anamolies at the end where start time is less than previous end time. Below code drops those rows and saves the cleaned transcripts in a new file. Since those anamolies are at the end, we can safely drop them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcripts(dir_name):\n",
    "    folders = sorted(os.listdir(dir_name))\n",
    "    for folder in folders:\n",
    "        # print(os.listdir(os.path.join(TRAIN_DIR, folder)))\n",
    "        # print(folder)\n",
    "        \n",
    "        print(f\"Cleaning {folder}\")\n",
    "        \n",
    "        id = folder.split(\"_\")[0]\n",
    "        \n",
    "        transcript = pd.read_csv(os.path.join(dir_name, folder, f\"{id}_Transcript.csv\"))\n",
    "        # print(transcript)\n",
    "        \n",
    "        start_time = transcript[\"Start_Time\"].values\n",
    "        end_time = transcript[\"End_Time\"].values\n",
    "\n",
    "        for i in range(1, len(start_time)):\n",
    "            if start_time[i] < end_time[i-1]:\n",
    "                print(f\"Anamoly found at index {i}\")\n",
    "                # drop that row\n",
    "                transcript.drop(i, inplace=True)\n",
    "\n",
    "        # save the cleaned transcript\n",
    "        transcript.to_csv(os.path.join(dir_name, folder, f\"{id}_Transcript_Clean.csv\"), index=False)\n",
    "        print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_clean_transcripts(dir_name, DEST_DIR):\n",
    "    if not os.path.exists(DEST_DIR):\n",
    "        os.makedirs(DEST_DIR)\n",
    "    folders = sorted(os.listdir(dir_name))\n",
    "    for folder in folders:\n",
    "        \n",
    "        print(f\"Copying {folder}\")\n",
    "        \n",
    "        id = folder.split(\"_\")[0]\n",
    "        \n",
    "        shutil.copyfile(os.path.join(dir_name, folder, f\"{id}_Transcript_Clean.csv\"), os.path.join(DEST_DIR, f\"{id}_Transcript.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 600_P\n",
      "Copying 602_P\n",
      "Copying 604_P\n",
      "Copying 605_P\n",
      "Copying 606_P\n",
      "Copying 607_P\n",
      "Copying 609_P\n",
      "Copying 615_P\n",
      "Copying 618_P\n",
      "Copying 619_P\n",
      "Copying 620_P\n",
      "Copying 622_P\n",
      "Copying 623_P\n",
      "Copying 624_P\n",
      "Copying 625_P\n",
      "Copying 626_P\n",
      "Copying 629_P\n",
      "Copying 631_P\n",
      "Copying 634_P\n",
      "Copying 635_P\n",
      "Copying 636_P\n",
      "Copying 637_P\n",
      "Copying 638_P\n",
      "Copying 640_P\n",
      "Copying 649_P\n",
      "Copying 650_P\n",
      "Copying 651_P\n",
      "Copying 652_P\n",
      "Copying 655_P\n",
      "Copying 656_P\n",
      "Copying 658_P\n",
      "Copying 659_P\n",
      "Copying 661_P\n",
      "Copying 663_P\n",
      "Copying 664_P\n",
      "Copying 666_P\n",
      "Copying 669_P\n",
      "Copying 676_P\n",
      "Copying 679_P\n",
      "Copying 682_P\n",
      "Copying 683_P\n",
      "Copying 688_P\n",
      "Copying 689_P\n",
      "Copying 691_P\n",
      "Copying 693_P\n",
      "Copying 696_P\n",
      "Copying 699_P\n",
      "Copying 705_P\n",
      "Copying 708_P\n",
      "Copying 709_P\n",
      "Copying 710_P\n",
      "Copying 712_P\n",
      "Copying 715_P\n",
      "Copying 716_P\n",
      "Copying 717_P\n",
      "Copying 718_P\n"
     ]
    }
   ],
   "source": [
    "DEST_DIR = \"../../raw-dataset/all_transcripts/test\"\n",
    "\n",
    "copy_clean_transcripts(TEST_DIR, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning 600_P\n",
      "-----\n",
      "Cleaning 602_P\n",
      "Anamoly found at index 54\n",
      "-----\n",
      "Cleaning 604_P\n",
      "-----\n",
      "Cleaning 605_P\n",
      "-----\n",
      "Cleaning 606_P\n",
      "-----\n",
      "Cleaning 607_P\n",
      "-----\n",
      "Cleaning 609_P\n",
      "-----\n",
      "Cleaning 615_P\n",
      "-----\n",
      "Cleaning 618_P\n",
      "-----\n",
      "Cleaning 619_P\n",
      "-----\n",
      "Cleaning 620_P\n",
      "-----\n",
      "Cleaning 622_P\n",
      "-----\n",
      "Cleaning 623_P\n",
      "-----\n",
      "Cleaning 624_P\n",
      "-----\n",
      "Cleaning 625_P\n",
      "-----\n",
      "Cleaning 626_P\n",
      "-----\n",
      "Cleaning 629_P\n",
      "-----\n",
      "Cleaning 631_P\n",
      "Anamoly found at index 56\n",
      "-----\n",
      "Cleaning 634_P\n",
      "-----\n",
      "Cleaning 635_P\n",
      "-----\n",
      "Cleaning 636_P\n",
      "-----\n",
      "Cleaning 637_P\n",
      "-----\n",
      "Cleaning 638_P\n",
      "-----\n",
      "Cleaning 640_P\n",
      "-----\n",
      "Cleaning 649_P\n",
      "-----\n",
      "Cleaning 650_P\n",
      "-----\n",
      "Cleaning 651_P\n",
      "-----\n",
      "Cleaning 652_P\n",
      "-----\n",
      "Cleaning 655_P\n",
      "-----\n",
      "Cleaning 656_P\n",
      "-----\n",
      "Cleaning 658_P\n",
      "-----\n",
      "Cleaning 659_P\n",
      "-----\n",
      "Cleaning 661_P\n",
      "Anamoly found at index 167\n",
      "-----\n",
      "Cleaning 663_P\n",
      "-----\n",
      "Cleaning 664_P\n",
      "Anamoly found at index 115\n",
      "-----\n",
      "Cleaning 666_P\n",
      "-----\n",
      "Cleaning 669_P\n",
      "-----\n",
      "Cleaning 676_P\n",
      "Anamoly found at index 65\n",
      "-----\n",
      "Cleaning 679_P\n",
      "Anamoly found at index 153\n",
      "Anamoly found at index 154\n",
      "-----\n",
      "Cleaning 682_P\n",
      "-----\n",
      "Cleaning 683_P\n",
      "Anamoly found at index 130\n",
      "-----\n",
      "Cleaning 688_P\n",
      "-----\n",
      "Cleaning 689_P\n",
      "Anamoly found at index 119\n",
      "-----\n",
      "Cleaning 691_P\n",
      "Anamoly found at index 125\n",
      "-----\n",
      "Cleaning 693_P\n",
      "Anamoly found at index 84\n",
      "-----\n",
      "Cleaning 696_P\n",
      "Anamoly found at index 109\n",
      "-----\n",
      "Cleaning 699_P\n",
      "-----\n",
      "Cleaning 705_P\n",
      "-----\n",
      "Cleaning 708_P\n",
      "Anamoly found at index 83\n",
      "-----\n",
      "Cleaning 709_P\n",
      "Anamoly found at index 103\n",
      "-----\n",
      "Cleaning 710_P\n",
      "-----\n",
      "Cleaning 712_P\n",
      "Anamoly found at index 115\n",
      "-----\n",
      "Cleaning 715_P\n",
      "-----\n",
      "Cleaning 716_P\n",
      "Anamoly found at index 138\n",
      "-----\n",
      "Cleaning 717_P\n",
      "-----\n",
      "Cleaning 718_P\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "clean_transcripts(TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Audio Based on Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DESTINATION_DIR = \"../../extracted_audio/train\"\n",
    "DEV_DESTINATION_DIR = \"../../extracted_audio/dev\"\n",
    "TEST_DESTINATION_DIR= \"../../extracted_audio/test\"\n",
    "\n",
    "dirs = [TRAIN_DESTINATION_DIR, DEV_DESTINATION_DIR, TEST_DESTINATION_DIR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_timestamps(src_dir, dest_dir):\n",
    "    src_folders = sorted(os.listdir(src_dir))\n",
    "    for folder in src_folders:\n",
    "        print(f\"Extracting audio for {folder}\") \n",
    "        id = folder.split(\"_\")[0]    \n",
    "        transcript = pd.read_csv(os.path.join(src_dir, folder, f\"{id}_Transcript_Clean.csv\"))\n",
    "        y, sr = lr.load(os.path.join(src_dir, folder, f\"{id}_AUDIO.wav\"))\n",
    "        \n",
    "        start_time = transcript[\"Start_Time\"].values\n",
    "        end_time = transcript[\"End_Time\"].values\n",
    "        \n",
    "        audio_chunks = []\n",
    "        for i in range(len(start_time)):\n",
    "            start = int(start_time[i]*sr)\n",
    "            end = int(end_time[i]*sr)\n",
    "            audio_chunks.extend(y[start:end])\n",
    "\n",
    "        # save the audio chunks\n",
    "        audio_chunks = np.array(audio_chunks)\n",
    "        \n",
    "        wavfile.write(os.path.join(dest_dir, f\"{id}_AUDIO.wav\"), sr, audio_chunks)\n",
    "        \n",
    "for dir in dirs:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio for 600_P\n",
      "Extracting audio for 602_P\n",
      "Extracting audio for 604_P\n",
      "Extracting audio for 605_P\n",
      "Extracting audio for 606_P\n",
      "Extracting audio for 607_P\n",
      "Extracting audio for 609_P\n",
      "Extracting audio for 615_P\n",
      "Extracting audio for 618_P\n",
      "Extracting audio for 619_P\n",
      "Extracting audio for 620_P\n",
      "Extracting audio for 622_P\n",
      "Extracting audio for 623_P\n",
      "Extracting audio for 624_P\n",
      "Extracting audio for 625_P\n",
      "Extracting audio for 626_P\n",
      "Extracting audio for 629_P\n",
      "Extracting audio for 631_P\n",
      "Extracting audio for 634_P\n",
      "Extracting audio for 635_P\n",
      "Extracting audio for 636_P\n",
      "Extracting audio for 637_P\n",
      "Extracting audio for 638_P\n",
      "Extracting audio for 640_P\n",
      "Extracting audio for 649_P\n",
      "Extracting audio for 650_P\n",
      "Extracting audio for 651_P\n",
      "Extracting audio for 652_P\n",
      "Extracting audio for 655_P\n",
      "Extracting audio for 656_P\n",
      "Extracting audio for 658_P\n",
      "Extracting audio for 659_P\n",
      "Extracting audio for 661_P\n",
      "Extracting audio for 663_P\n",
      "Extracting audio for 664_P\n",
      "Extracting audio for 666_P\n",
      "Extracting audio for 669_P\n",
      "Extracting audio for 676_P\n",
      "Extracting audio for 679_P\n",
      "Extracting audio for 682_P\n",
      "Extracting audio for 683_P\n",
      "Extracting audio for 688_P\n",
      "Extracting audio for 689_P\n",
      "Extracting audio for 691_P\n",
      "Extracting audio for 693_P\n",
      "Extracting audio for 696_P\n",
      "Extracting audio for 699_P\n",
      "Extracting audio for 705_P\n",
      "Extracting audio for 708_P\n",
      "Extracting audio for 709_P\n",
      "Extracting audio for 710_P\n",
      "Extracting audio for 712_P\n",
      "Extracting audio for 715_P\n",
      "Extracting audio for 716_P\n",
      "Extracting audio for 717_P\n",
      "Extracting audio for 718_P\n"
     ]
    }
   ],
   "source": [
    "extract_audio_from_timestamps(TEST_DIR, TEST_DESTINATION_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest)",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
